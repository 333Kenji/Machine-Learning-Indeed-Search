{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "analyzed-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['font.size'] = 17\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b055407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'../app/data/processed_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c7eaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"job descriptiondata scientist, marketingsan diego, ca /analytics – data science /full-timeheadquartered in san diego, we serve as a leading provider of working capital ($5k - $1.5m) to the small and medium-sized businesses that fuel our country. since 2008, we have prided ourselves on our collaborative, innovative, and customer-focused approach. enjoying a period of unprecedented growth, driven by the combination of cutting-edge technology, human touch, and unwavering integrity, we are looking to add to our people-first culture, with highly motivated and results-oriented professionals, to push the limits of what's possible while creating value for all of our partners.we are seeking a mid-level to senior level statistician, quantitative modeling specialist, or data scientist to join our analytics team and build predictive models for marketing. if you have exceptional analytical, quantitative and problem-solving skills, demonstrated experience designing and implementing predictive models and analytics in marketing, a proven track record of bringing thought leadership to problems, and the desire to make a rapid impact on the success of the business, this is an opportunity for you.the ideal candidate has an advanced degree in statistics, economics, mathematics or a related field; strong inner motivation to work hard, learn and grow; intellectual curiosity and honesty; attention to detail; and excellent interpersonal skills. this position reports to the svp of analytics.responsibilitiesresearch, devise, test and implement innovative statistical models for marketing and related areas of the business.work independently and in collaboration with others on the team.identify relevant data sources and data sets to deliver insights and analysis for business decision-making.source, cleanse and verify data.work closely with analytics and technology teams to deploy models in production and to monitor and test deployed models.communicate analytics solutions to parties across the business in the form of presentations and other materials.own the accuracy and precision of all work.required qualificationsb.a. or above in statistics, economics, applied mathematics, or related discipline (master’s or above preferred).2-5 years of experience in model design and implementation in marketing for fintech or related industry.independence and thought leadership in problem solving; demonstrated ability to own a problem from initial data analysis to model research, development, testing and operationalization.strong understanding of and experience with marketing data flows and methods for audience segmentation, customer lifetime value, and attribution.fluency with statistical modeling and machine learning methods.fluency with sql and python.fluency with descriptive data analysis and presentation.strong attention to detail and organizational skills.intellectual curiosity and creativity.strong written and verbal communication skills.we offercompetitive compensation package.great medical, vision and dental benefits.health savings account.flexible spending accounts.life and disability insurance.fantastic 401k with matching contribution.sick, vacation, and holidays.gym membership contribution.employee assistance program (eap) – mental health support.online commuter benefits.internal referral program.fun team and company events.start-up culture, within an established business with 13 years of experience.great central location in san diego – easy access from highway.we are an equal opportunity employer (eoe) and takes great pride in building a diverse work environment. qualified applicants are considered for employment without regard to age, race, religion, gender, national origin, sexual orientation, disability or veteran status.job type: full-timepay: $145,000.00 - $150,000.00 per yearbenefits:dental insuranceflexible schedulehealth insurancepaid time offvision insuranceschedule:8 hour shiftday shiftmonday to fridayeducation:master's (preferred)experience:python: 1 year (preferred)sql: 1 year (preferred)data scientists & statisticians: 1 year (preferred)work location: remote identify relevant data sources and data sets to deliver insights and analysis for business decision-making. source, cleanse and verify data.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2618bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c14552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "    sentences = data.split('.')\n",
    "    clean_sentences = []\n",
    "    for i in sentences:\n",
    "        clean_sentence = re.sub(r'[?|!|\\'|\"|#|/|-|,(|)|$|-|' '|:]',r'',i)\n",
    "        clean_sentence = re.sub(r'[?|!|\\'|\"|#|/|-|,(|)|$|(0-9)]',r'',clean_sentence.strip(' '))\n",
    "        if len(clean_sentence.strip()) > 1:\n",
    "            clean_sentences.append(clean_sentence)\n",
    "    done_sent = ''\n",
    "    for i in clean_sentences:\n",
    "        done_sent += (' '+i)\n",
    "    return done_sent.strip()\n",
    "    \n",
    "\n",
    "data['cleaned'] = data.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043cdcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job descriptiondata scientist marketingsan diego ca analytics – data science full-timeheadquartered in san diego we serve as a leading provider of working capital k -  m to the small and medium-sized businesses that fuel our country since  we have prided ourselves on our collaborative innovative and customer-focused approach enjoying a period of unprecedented growth driven by the combination of cutting-edge technology human touch and unwavering integrity we are looking to add to our people-first culture with highly motivated and results-oriented professionals to push the limits of whats possible while creating value for all of our partners we are seeking a mid-level to senior level statistician quantitative modeling specialist or data scientist to join our analytics team and build predictive models for marketing if you have exceptional analytical quantitative and problem-solving skills demonstrated experience designing and implementing predictive models and analytics in marketing a proven track record of bringing thought leadership to problems and the desire to make a rapid impact on the success of the business this is an opportunity for you the ideal candidate has an advanced degree in statistics economics mathematics or a related field; strong inner motivation to work hard learn and grow; intellectual curiosity and honesty; attention to detail; and excellent interpersonal skills this position reports to the svp of analytics responsibilitiesresearch devise test and implement innovative statistical models for marketing and related areas of the business work independently and in collaboration with others on the team identify relevant data sources and data sets to deliver insights and analysis for business decision-making source cleanse and verify data work closely with analytics and technology teams to deploy models in production and to monitor and test deployed models communicate analytics solutions to parties across the business in the form of presentations and other materials own the accuracy and precision of all work required qualificationsb or above in statistics economics applied mathematics or related discipline master’s or above preferred - years of experience in model design and implementation in marketing for fintech or related industry independence and thought leadership in problem solving; demonstrated ability to own a problem from initial data analysis to model research development testing and operationalization strong understanding of and experience with marketing data flows and methods for audience segmentation customer lifetime value and attribution fluency with statistical modeling and machine learning methods fluency with sql and python fluency with descriptive data analysis and presentation strong attention to detail and organizational skills intellectual curiosity and creativity strong written and verbal communication skills we offercompetitive compensation package great medical vision and dental benefits health savings account flexible spending accounts life and disability insurance fantastic k with matching contribution sick vacation and holidays gym membership contribution employee assistance program eap – mental health support online commuter benefits internal referral program fun team and company events start-up culture within an established business with  years of experience great central location in san diego – easy access from highway we are an equal opportunity employer eoe and takes great pride in building a diverse work environment qualified applicants are considered for employment without regard to age race religion gender national origin sexual orientation disability or veteran status job type full-timepay   per yearbenefitsdental insuranceflexible schedulehealth insurancepaid time offvision insuranceschedule hour shiftday shiftmonday to fridayeducationmasters preferredexperiencepython  year preferredsql  year preferreddata scientists & statisticians  year preferredwork location remote identify relevant data sources and data sets to deliver insights and analysis for business decision-making source cleanse and verify data'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edd3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "    sentences = data.split('.')\n",
    "    clean_sentences = []\n",
    "    for i in sentences:\n",
    "        clean_sentence = re.sub(r'[?|!|\\'|\"|#|/|-|,(|)|$|-|' '|:]',r'',i)\n",
    "        clean_sentence = re.sub(r'[?|!|\\'|\"|#|/|-|,(|)|$|-|' '|:]',r'',clean_sentence)\n",
    "        clean_sentence = \" \".join(re.findall(\"[(a-zA-Z,&)]+\", clean_sentence))\n",
    "        clean_sentences.append(clean_sentence)\n",
    "    clean_text = ''\n",
    "    for i in clean_sentences:\n",
    "        clean_text += (' '+i)\n",
    "    return clean_text.strip(' ')\n",
    "\n",
    "    \n",
    "\n",
    "data['cleaned'] = data.text.apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96973395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'li remote about eab at eab our mission is to make education smarter and our communities stronger we work with more than institutions to drive transformative change through data driven insights and best in class capabilities from kindergarten to college to career eab partners with leaders and practitioners to accelerate progress and drive results across five major areas enrollment student success institutional strategy data & analytics and diversity equity and inclusion de&i we work with each partner differently tailoring our portfolio of research technology and marketing and enrollment solutions to meet the unique needs of every leadership team as well as the students and employees they serve at eab we serve not only our partner institutions but each other thats why we are always working to make sure our employees love their jobs and are invested in their communities see how weve been recognized for this dedication to our employees by checking out our recent awards for more information visit our careers page the role in brief associate data scientist this position is based in washington d c remote possible job description eab is seeking aspiring data scientists of diverse talents and interests to help grow our industry leading software platforms artificial intelligence and machine learning capabilities whether you are by nature a researcher with a quantitative bent interested in tackling some of the most impactful questions in the social sciences or a software engineer who wants to build a world class machine learning platform you can carve out a place for yourself on our team we are a medium sized team working to discover build and scale aiml solutions that help colleges and universities support their students from the application phase to graduation and beyond in a positive inquisitive and collaborative environment primary responsibilitiescollaborate with data engineers and software engineers to integrate research driven machine learning models into production software systemsbuild internal tools for data scienceanalytics workflowsmanage data processing pipelines for analyzing terabyte scale data from multiple sourceswrite python code using current best practicescoordinate with product managers software engineers and customer facing teamsbasic qualificationsbachelor s degree in a quantitative field or equivalent experienceprogramming skills in pythonexperience using sql for data cleansing transformation summarization or analysisability to communicate and collaborate with both technical and non technical team membersconscientious curious dedicated and quality focusedideal qualificationsexperience with machine learning statistics and the scientific methodprofessional experience with software engineering data warehousing linux systemsexperience with aws or other cloud based server management and machine learning servicescommitment to valuing diversity practicing inclusive behaviors and contributing to an equitable working and continual learning environment in support of eab s de&i promiseif you ve reached this section of the job description and are unsure of whether to apply please do at eab we welcome diversity of background and experience we would encourage you to submit an application if this is a role you would be passionate about doing every day benefits consistent with our belief that our employees are our most valuable resource eab offers a competitive and inclusive benefits package medical dental and vision insurance dependents and domestic partners eligible k retirement plan with company match days of pto annually in addition to paid firm holidaysdaytime leave policy for community service or fitness activities up to hours a month eachpaid parental leave for birthing or non birthing parentsphase back to work program for employees returning from parental leaveinfertility treatment coverage and adoption or surrogacy assistancewellness programs including gym discounts and incentives to promote healthy livingdynamic growth opportunities with merit based promotion philosophybenefits kick in day one see the full details here at eab we believe that to fulfill our mission to make education smarter and our communities stronger we need team members who bring a diversity of perspectives to the table and are committed to fostering a workplace where each team member is valued respected and heard to that end eab is an equal opportunity employer and we make employment decisions on the basis of qualifications merit and business need we don t discriminate on the basis of race religion color sex gender identity or expression sexual orientation age non disqualifying physical or mental disability national origin veteran status or any other basis covered by appropriate law experience with machine learning statistics and the scientific method collaborate with data engineers and software engineers to integrate research driven'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleaned[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e87e7",
   "metadata": {},
   "source": [
    "### 4.1 Target\n",
    "Before I can begin splitting the data I need to set the target for my methodology of training four seperate logistic regression models. I'm doing this because I'd like my classifications to be as accurate as possible, and also, by building my NLP strategy around a particular label, i.e. finding common words for that label as opposed to being generalized through the entire corpus\\\n",
    "\n",
    "I'm going to one-hot-encode the target feature so I can select each of the next columns as my y - one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f059c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['company','rating','job_title','state','city','cleaned','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30f30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, dtype='int')\n",
    "targets = ohe.fit_transform(pd.DataFrame(data.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b9e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.DataFrame(targets,columns=['Q1','Q2','Q3','Q4','unk'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea516b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>rating</th>\n",
       "      <th>job_title</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>target</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>unk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>online technical services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>data scientist - marketing</td>\n",
       "      <td>remote</td>\n",
       "      <td>remote</td>\n",
       "      <td>job descriptiondata scientist marketingsan die...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>west cap</td>\n",
       "      <td>3.5</td>\n",
       "      <td>data scientist, botguard</td>\n",
       "      <td>ny</td>\n",
       "      <td>remote in new york</td>\n",
       "      <td>human was founded in in a brooklyn sci fi book...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>techtrueup</td>\n",
       "      <td>3.8</td>\n",
       "      <td>mcs data scientist</td>\n",
       "      <td>remote</td>\n",
       "      <td>remote</td>\n",
       "      <td>description data scientist fully remote develo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eab</td>\n",
       "      <td>3.7</td>\n",
       "      <td>associate data scientist</td>\n",
       "      <td>dc</td>\n",
       "      <td>remote in washington</td>\n",
       "      <td>li remote about eab at eab our mission is to m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>redfin</td>\n",
       "      <td>3.4</td>\n",
       "      <td>senior data analyst - tour support (remote eli...</td>\n",
       "      <td>remote</td>\n",
       "      <td>remote</td>\n",
       "      <td>this position is a remote eligible position yo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company  rating  \\\n",
       "0  online technical services     3.7   \n",
       "1                   west cap     3.5   \n",
       "2                 techtrueup     3.8   \n",
       "3                        eab     3.7   \n",
       "4                     redfin     3.4   \n",
       "\n",
       "                                           job_title   state  \\\n",
       "0                         data scientist - marketing  remote   \n",
       "1                           data scientist, botguard      ny   \n",
       "2                                 mcs data scientist  remote   \n",
       "3                           associate data scientist      dc   \n",
       "4  senior data analyst - tour support (remote eli...  remote   \n",
       "\n",
       "                   city                                            cleaned  \\\n",
       "0                remote  job descriptiondata scientist marketingsan die...   \n",
       "1    remote in new york  human was founded in in a brooklyn sci fi book...   \n",
       "2                remote  description data scientist fully remote develo...   \n",
       "3  remote in washington  li remote about eab at eab our mission is to m...   \n",
       "4                remote  this position is a remote eligible position yo...   \n",
       "\n",
       "   target  Q1  Q2  Q3  Q4  unk  \n",
       "0     4.0   0   0   0   1    0  \n",
       "1     2.0   0   1   0   0    0  \n",
       "2     3.0   0   0   1   0    0  \n",
       "3     1.0   1   0   0   0    0  \n",
       "4     2.0   0   1   0   0    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(targets)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16b9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['target','unk'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1edd6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "\n",
    "data['comment_text'] = data['cleaned'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404132b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job descriptiondata scientist marketingsan diego ca analyt data scienc full timeheadquart in san diego we serv as a lead provid of work capit k m to the small and medium size busi that fuel our countri sinc we have pride ourselv on our collabor innov and custom focus approach enjoy a period of unpreced growth driven by the combin of cut edg technolog human touch and unwav integr we are look to add to our peopl first cultur with high motiv and result orient profession to push the limit of what possibl while creat valu for all of our partner we are seek a mid level to senior level statistician quantit model specialist or data scientist to join our analyt team and build predict model for market if you have except analyt quantit and problem solv skill demonstr experi design and implement predict model and analyt in market a proven track record of bring thought leadership to problem and the desir to make a rapid impact on the success of the busi this is an opportun for you the ideal candid has an advanc degre in statist econom mathemat or a relat field strong inner motiv to work hard learn and grow intellectu curios and honesti attent to detail and excel interperson skill this posit report to the svp of analyt responsibilitiesresearch devis test and implement innov statist model for market and relat area of the busi work independ and in collabor with other on the team identifi relev data sourc and data set to deliv insight and analysi for busi decis make sourc cleans and verifi data work close with analyt and technolog team to deploy model in product and to monitor and test deploy model communic analyt solut to parti across the busi in the form of present and other materi own the accuraci and precis of all work requir qualificationsb a or abov in statist econom appli mathemat or relat disciplin master s or abov prefer year of experi in model design and implement in market for fintech or relat industri independ and thought leadership in problem solv demonstr abil to own a problem from initi data analysi to model research develop test and operation strong understand of and experi with market data flow and method for audienc segment custom lifetim valu and attribut fluenci with statist model and machin learn method fluenci with sql and python fluenci with descript data analysi and present strong attent to detail and organiz skill intellectu curios and creativ strong written and verbal communic skill we offercompetit compens packag great medic vision and dental benefit health save account flexibl spend account life and disabl insur fantast k with match contribut sick vacat and holiday gym membership contribut employe assist program eap mental health support onlin commut benefit intern referr program fun team and compani event start up cultur within an establish busi with year of experi great central locat in san diego easi access from highway we are an equal opportun employ eoe and take great pride in build a divers work environ qualifi applic are consid for employ without regard to age race religion gender nation origin sexual orient disabl or veteran status job type full timepay per yearbenefitsdent insuranceflex schedulehealth insurancepaid time offvis insuranceschedul hour shiftday shiftmonday to fridayeducationmast preferredexperiencepython year preferredsql year preferreddata scientist & statistician year preferredwork locat remot identifi relev data sourc and data set to deliv insight and analysi for busi decis make sourc cleans and verifi data'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.comment_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7348a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job descriptiondata scientist marketingsan diego ca analytics data science full timeheadquartered in san diego we serve a a leading provider of working capital k m to the small and medium sized business that fuel our country since we have prided ourselves on our collaborative innovative and customer focused approach enjoying a period of unprecedented growth driven by the combination of cutting edge technology human touch and unwavering integrity we are looking to add to our people first culture with highly motivated and result oriented professional to push the limit of whats possible while creating value for all of our partner we are seeking a mid level to senior level statistician quantitative modeling specialist or data scientist to join our analytics team and build predictive model for marketing if you have exceptional analytical quantitative and problem solving skill demonstrated experience designing and implementing predictive model and analytics in marketing a proven track record of bringing thought leadership to problem and the desire to make a rapid impact on the success of the business this is an opportunity for you the ideal candidate ha an advanced degree in statistic economics mathematics or a related field strong inner motivation to work hard learn and grow intellectual curiosity and honesty attention to detail and excellent interpersonal skill this position report to the svp of analytics responsibilitiesresearch devise test and implement innovative statistical model for marketing and related area of the business work independently and in collaboration with others on the team identify relevant data source and data set to deliver insight and analysis for business decision making source cleanse and verify data work closely with analytics and technology team to deploy model in production and to monitor and test deployed model communicate analytics solution to party across the business in the form of presentation and other material own the accuracy and precision of all work required qualificationsb a or above in statistic economics applied mathematics or related discipline master s or above preferred year of experience in model design and implementation in marketing for fintech or related industry independence and thought leadership in problem solving demonstrated ability to own a problem from initial data analysis to model research development testing and operationalization strong understanding of and experience with marketing data flow and method for audience segmentation customer lifetime value and attribution fluency with statistical modeling and machine learning method fluency with sql and python fluency with descriptive data analysis and presentation strong attention to detail and organizational skill intellectual curiosity and creativity strong written and verbal communication skill we offercompetitive compensation package great medical vision and dental benefit health saving account flexible spending account life and disability insurance fantastic k with matching contribution sick vacation and holiday gym membership contribution employee assistance program eap mental health support online commuter benefit internal referral program fun team and company event start up culture within an established business with year of experience great central location in san diego easy access from highway we are an equal opportunity employer eoe and take great pride in building a diverse work environment qualified applicant are considered for employment without regard to age race religion gender national origin sexual orientation disability or veteran status job type full timepay per yearbenefitsdental insuranceflexible schedulehealth insurancepaid time offvision insuranceschedule hour shiftday shiftmonday to fridayeducationmasters preferredexperiencepython year preferredsql year preferreddata scientist & statistician year preferredwork location remote identify relevant data source and data set to deliver insight and analysis for business decision making source cleanse and verify data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def stemming(sentence):\n",
    "    LemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = lemmatizer.lemmatize(word)\n",
    "        LemSentence += stem\n",
    "        LemSentence += \" \"\n",
    "    LemSentence = LemSentence.strip()\n",
    "    return LemSentence\n",
    "\n",
    "\n",
    "data['comment_text_lem'] = data['cleaned'].apply(stemming)\n",
    "data.comment_text_lem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "960258da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['cleaned','comment_text'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data = data.drop(['Q2','Q3','Q4'], axis=1)\n",
    "q2_data = data.drop(['Q1','Q3','Q4'], axis=1)\n",
    "q3_data = data.drop(['Q1','Q2','Q4'], axis=1)\n",
    "q4_data = data.drop(['Q1','Q2','Q3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74bf2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = q1_data.drop(['Q1'], axis=1)\n",
    "y = q1_data['Q1']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y , test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28344f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>rating</th>\n",
       "      <th>job_title</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>comment_text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>spotify</td>\n",
       "      <td>4.3</td>\n",
       "      <td>data scientist, advertising economics</td>\n",
       "      <td>ny</td>\n",
       "      <td>remote in new york</td>\n",
       "      <td>data research &amp; insightsdata scienceat spotify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>s&amp;p global</td>\n",
       "      <td>3.9</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>tn</td>\n",
       "      <td>remote in nashville</td>\n",
       "      <td>segment market intelligence the role data scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>cybercoders</td>\n",
       "      <td>3.7</td>\n",
       "      <td>remote senior data analyst</td>\n",
       "      <td>ca</td>\n",
       "      <td>remote in san francisco</td>\n",
       "      <td>remote senior data analyst if you are a senior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>galaxe.solutions</td>\n",
       "      <td>2.5</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>wi</td>\n",
       "      <td>remote in milwaukee</td>\n",
       "      <td>what you will dowell acquainted with the dba r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>galaxe.solutions</td>\n",
       "      <td>2.5</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>wi</td>\n",
       "      <td>remote in milwaukee</td>\n",
       "      <td>what you will dowell acquainted with the dba r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>online technical services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>data scientist - marketing</td>\n",
       "      <td>remote</td>\n",
       "      <td>remote</td>\n",
       "      <td>job descriptiondata scientist marketingsan die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>cybercoders</td>\n",
       "      <td>3.7</td>\n",
       "      <td>principal data scientist</td>\n",
       "      <td>wa</td>\n",
       "      <td>remote in seattle</td>\n",
       "      <td>principal data scientist if you are a principa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>sparkcognition</td>\n",
       "      <td>4.4</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>tx</td>\n",
       "      <td>remote in austin</td>\n",
       "      <td>voted best place to work in austin best paying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>amadeus</td>\n",
       "      <td>3.9</td>\n",
       "      <td>principal data scientist - network planning fo...</td>\n",
       "      <td>remote</td>\n",
       "      <td>remote</td>\n",
       "      <td>summary of the rolewhere to fly when to fly wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>ericsson</td>\n",
       "      <td>4.1</td>\n",
       "      <td>data scientist (techn) -remote</td>\n",
       "      <td>ca</td>\n",
       "      <td>remote in santa clara</td>\n",
       "      <td>we are currently looking for a data scientist ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company  rating  \\\n",
       "995                    spotify     4.3   \n",
       "507                 s&p global     3.9   \n",
       "334                cybercoders     3.7   \n",
       "848           galaxe.solutions     2.5   \n",
       "294           galaxe.solutions     2.5   \n",
       "..                         ...     ...   \n",
       "87   online technical services     3.7   \n",
       "330                cybercoders     3.7   \n",
       "466             sparkcognition     4.4   \n",
       "121                    amadeus     3.9   \n",
       "860                   ericsson     4.1   \n",
       "\n",
       "                                             job_title   state  \\\n",
       "995              data scientist, advertising economics      ny   \n",
       "507                                     data scientist      tn   \n",
       "334                         remote senior data analyst      ca   \n",
       "848                                       data analyst      wi   \n",
       "294                                       data analyst      wi   \n",
       "..                                                 ...     ...   \n",
       "87                          data scientist - marketing  remote   \n",
       "330                           principal data scientist      wa   \n",
       "466                          machine learning engineer      tx   \n",
       "121  principal data scientist - network planning fo...  remote   \n",
       "860                     data scientist (techn) -remote      ca   \n",
       "\n",
       "                        city  \\\n",
       "995       remote in new york   \n",
       "507      remote in nashville   \n",
       "334  remote in san francisco   \n",
       "848      remote in milwaukee   \n",
       "294      remote in milwaukee   \n",
       "..                       ...   \n",
       "87                    remote   \n",
       "330        remote in seattle   \n",
       "466         remote in austin   \n",
       "121                   remote   \n",
       "860    remote in santa clara   \n",
       "\n",
       "                                      comment_text_lem  \n",
       "995  data research & insightsdata scienceat spotify...  \n",
       "507  segment market intelligence the role data scie...  \n",
       "334  remote senior data analyst if you are a senior...  \n",
       "848  what you will dowell acquainted with the dba r...  \n",
       "294  what you will dowell acquainted with the dba r...  \n",
       "..                                                 ...  \n",
       "87   job descriptiondata scientist marketingsan die...  \n",
       "330  principal data scientist if you are a principa...  \n",
       "466  voted best place to work in austin best paying...  \n",
       "121  summary of the rolewhere to fly when to fly wh...  \n",
       "860  we are currently looking for a data scientist ...  \n",
       "\n",
       "[824 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 824 entries, 995 to 860\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   company           824 non-null    object \n",
      " 1   rating            824 non-null    float64\n",
      " 2   job_title         824 non-null    object \n",
      " 3   state             824 non-null    object \n",
      " 4   city              824 non-null    object \n",
      " 5   comment_text_lem  824 non-null    object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 45.1+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus = x_train.comment_text_lem\n",
    "def vect(sentence):\n",
    "    return vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "vectorized = pd.DataFrame(data['comment_text_lem'].apply(vect))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159855b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "corpus = x_train.comment_text_lem\n",
    "def vect(sentence):\n",
    "    vectorizer.fit_transform(corpus)\n",
    "    return vectorizer.get_feature_names_out()\n",
    "    \n",
    "vectorized2 = pd.DataFrame(data['comment_text_lem'].apply(vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6379704b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "507      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "334      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "848      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "294      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "                             ...                        \n",
       "87       (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "330      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "466      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "121      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "860      (0, 3687)\\t0.03732987068641745\\n  (0, 2710)\\...\n",
       "Name: text, Length: 824, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler_features = num_cols\n",
    "nlp_cols = ['comment_text_lem']\n",
    "le_cols = ['city','state','job_title','company']\n",
    "scal_cols = ['rating']\n",
    "\n",
    "one_hot_encoder = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='if_binary'))\n",
    "])\n",
    "\n",
    "vect = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer())\n",
    "])\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "label_encoder = Pipeline(steps=[\n",
    "    ('label_enc', LabelEncoder())\n",
    "])\n",
    "scaler_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "minmax_scalar_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('ord_cat', ordinal_cat_encoder, ordinal_cat_features),\n",
    "        #('ord',ord_enc,le_cols),\n",
    "        #('ohe', one_hot_encoder, nom_cols),\n",
    "        #('binarize', one_hot_encoder, bin_cols),\n",
    "        ('vect',vect,nlp_cols),\n",
    "        #('label_enc', label_encoder, le_cols),\n",
    "        #('scaler', scaler_transformer,scal_cols)\n",
    "        #('minmax_scaler', minmax_scalar_transformer,scaler_features)\n",
    "    ],remainder='drop'\n",
    ")\n",
    "\n",
    "transformer = Pipeline(steps=[('preprocessor', preprocessor)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = pd.DataFrame(transformer.fit_transform(x_train))\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", transformer), \n",
    "        (\"logreg\", LogisticRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80176a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_x_train, q1_y_train, q1_x_train, q1_y_train, \n",
    "train, test = train_test_split(X,y, random_state=42, test_size=0.30, shuffle=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['id','comment_text'], axis=1)x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['id','comment_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])for category in categories:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c3a26",
   "metadata": {},
   "source": [
    "### 4.2 X, y, and Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[bin_cols+nom_cols+num_cols]\n",
    "y = data[target]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y , test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f801980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47530a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['company','job_title', 'state', 'city']\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#perform one-hot encoding on 'team' column \n",
    "encodered_data = pd.DataFrame(encoder.fit_transform(data[cols]).toarray())\n",
    "\n",
    "#merge one-hot encoded columns back with original DataFrame\n",
    "final_df = data.join(encodered_data)\n",
    "final_df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "#view final df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(data.cleaned[0].strip(' '))\n",
    "my_var = [w for w in word_tokens if (not w in stop_words and len(w) > 1)]\n",
    "my_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91621bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = [lemmatizer.lemmatize(token) for token in my_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8050c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8733670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit_transform(data.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43548912",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672019b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2859a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"word\", tokenizer=word_tokenize,\n",
    "    preprocessor=None, stop_words='english', max_features=None)    \n",
    "\n",
    "tfidf = count_vectorizer.fit_transform(data['cleaned'])\n",
    "\n",
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c3bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bde58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81612031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train = pd.DataFrame(tfidf.todense(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in class_train.columns:\n",
    "    z = sum(class_train[i])/len(data)\n",
    "    lst.append(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc04a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'salary':'salary_main'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['text','cleaned']\n",
    "data.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f94925",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81289ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = data.join(class_train)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415dd88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.salary_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a575eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = final_df.salary_main[final_df.salary_main.notna()]\n",
    "x = final_df.drop('salary_main',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f34b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = final_df.salary_main[final_df.salary_main.notna()]\n",
    "x = final_df.drop('salary_main',axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.30, shuffle=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a49984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a88b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e30d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d26a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', class_weight='balanced')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d80af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, hamming_loss,precision_score,recall_score,f1_score,classification_report\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy :\",accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a401de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Hamming loss \",hamming_loss(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc63768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMicro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMacro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report\")\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb52f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a4119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da9383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d1da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac83f05b37eb5c5c49ba67e50f0047ddfbc4b30205fc79ee5f327b9c0ac37f55"
  },
  "kernelspec": {
   "display_name": "Python [conda env:indeedapp]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
