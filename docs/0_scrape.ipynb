{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "import time\n",
    "import re\n",
    "# current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to test for captcha block or IP ban\n",
    "def get_URL(position,location):\n",
    "    #from torrequest import TorRequest\n",
    "    \"\"\"[Build a template url for a dummy call to verify the site isn't returning a captcha]\n",
    "    Args:\n",
    "        position ([string]): [job for query]\n",
    "        location ([string]): [location for query]\n",
    "    Returns:\n",
    "        [string]: [formatted url]\n",
    "    \"\"\"\n",
    "    template = 'https://www.indeed.com/jobs?q={}&l={}&fromage=1&sort=date'\n",
    "                \n",
    "    position = position.replace(' ', '%20')\n",
    "    location = location.replace(' ', '+')\n",
    "    url = template.format(position,location)\n",
    "    return url\n",
    "\n",
    "\n",
    "# from torrequest import TorRequest\n",
    "# tr=TorRequest(password='your_super_secure_password')\n",
    "position = 'data scientist'\n",
    "location = 'california'\n",
    "# tr.reset_identity()\n",
    "response = requests.get(get_URL(position,location))\n",
    "# This will either return an HTML block for a captcha or of a search result\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchResults = soup.find('div', id='mosaic-provider-jobcards')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinedsearchResults = searchResults.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(refinedsearchResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = searchResults.children\n",
    "lst = []\n",
    "for i in z:\n",
    "    lst.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = lst[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "refinedsearchResults = soup.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "        \n",
    "\n",
    "raw_posts = []\n",
    "for post in refinedsearchResults:\n",
    "        raw_posts.append(post)\n",
    "        n = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = raw_posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = z.find('a', href=True)\n",
    "url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\\w+')).attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postDate = z.find('span', 'date').text\n",
    "extractDate = datetime.today().strftime('%Y-%m-%d')\n",
    "summary = z.find('div', 'job-snippet').text.strip().replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = z.find('a', attrs={'class':'turnstileLink companyOverviewLink'}).text.strip()\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = z.find('a', attrs={'class':'jcs-JobTitle'}).text.strip()\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_features(job_url):\n",
    "    \"\"\"Parses each job description, searching for and extracting values for features\n",
    "\n",
    "    Args:\n",
    "        job_url (string): http address of each job posting\n",
    "\n",
    "    Returns:\n",
    "        tuple: job feature values\n",
    "    \"\"\"\n",
    "    response_job_desc = requests.get(job_url)\n",
    "    soup = BeautifulSoup(response_job_desc.text, 'html.parser')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        salary_and_jType = soup.find('div', id='salaryInfoAndJobType').text.strip()\n",
    "    except:\n",
    "        salary_and_jType = None\n",
    "    if salary_and_jType == None:\n",
    "        try:\n",
    "            salary_and_jType = soup.find('div',id=\"icl-u-xs-block jobsearch-ReqAndQualSection-item--title\").text.replace(\"\\n\", \"\").strip()\n",
    "        except:\n",
    "            salary_and_jType = None\n",
    "    #TODO get benefits from its designated section\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        sal_guide_items = []\n",
    "        items = soup.find('ul',class_='css-1lyr5hv eu4oa1w0')\n",
    "        for i in items:\n",
    "            sal_guide_items.append(i.text)\n",
    "    except:\n",
    "        sal_guide_items = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        salfromsection = soup.find('span',class_='icl-u-xs-mr--xs').text\n",
    "    except:\n",
    "        salfromsection = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        job_type_items = []\n",
    "        job_type_from_section = soup.find('div',class_='jobsearch-JobDescriptionSection-sectionItem').next_sibling.children\n",
    "        for i in job_type_from_section:\n",
    "            if i.text == 'Job Type':\n",
    "                continue\n",
    "            else:\n",
    "                job_type_items.append(i.text)\n",
    "    except:\n",
    "        job_type_items = None\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        requirements = soup.find(class_=\"icl-u-xs-block jobsearch-ReqAndQualSection-item--title\").text.replace(\"\\n\", \"\").strip()      \n",
    "\n",
    "    except:\n",
    "        requirements = None\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        description = soup.find(id=\"jobDescriptionText\").text.replace('\\n', '')\n",
    "    except:\n",
    "        description = None\n",
    "        \n",
    "        \n",
    "    # A nifty little workaround for evading detection.\n",
    "    time.sleep(.5+random()*3)\n",
    "    #TODO assess h2 tags commonalities to determine if these section descriptions are from Indeed or are at least of only a few variations.\n",
    "        #you could then distinguish the description into sections and conduct NLP etc each.\n",
    "    raw_desc_soup = soup\n",
    "    return salary_and_jType, sal_guide_items, salfromsection, job_type_items, requirements, description, raw_desc_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO condense these with lists, particularly fields that have .text.strip()\n",
    "def get_features(post):\n",
    "    \"\"\"parses search results and extracts basic job feature values,\n",
    "        then combines this with output of 'get_desc_features' function.\n",
    "\n",
    "    Args:\n",
    "        post (string): response for each post in search results page\n",
    "\n",
    "    Returns:\n",
    "        dict: single-feature deep dictionary of features (dictionary keys) and their values (dictionary values)\n",
    "    \"\"\"\n",
    "    datapoint_dict = {}\n",
    "\n",
    "    title = post.find('h2',\n",
    "              attrs={'class': lambda e: e.startswith('jobTitle') if e else False}).text.replace('new', '')\n",
    "\n",
    "    company = post.find('span', 'companyName').text.strip()\n",
    "    try:\n",
    "        rating = post.find('span', 'ratingNumber').text\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    location = post.find('div', 'companyLocation').text.strip()\n",
    "    postDate = post.find('span', 'date').text\n",
    "    extractDate = datetime.today().strftime('%Y-%m-%d')\n",
    "    summary = post.find('div', 'job-snippet').text.strip().replace('\\n', ' ')\n",
    "    url = 'https://www.indeed.com'+ post.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\\w+')).attrs['href']\n",
    "\n",
    "    try:\n",
    "        estimated_salary = post.find('span','estimated-salary').text.strip()\n",
    "    except:\n",
    "        estimated_salary = None\n",
    "    try:\n",
    "        salary = post.find('div','metadata salary-snippet-container').text.strip()\n",
    "    except:\n",
    "        salary = None\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    salary_and_jType, sal_guide_items, salfromsection, job_type_items, requirements, description, raw_desc_soup = get_desc_features(url)\n",
    "    datapoint_dict = {\n",
    "                        'title':title,\n",
    "                        'company':company,\n",
    "                        'rating':rating,\n",
    "                        'location':location,\n",
    "                        'salary':salary,\n",
    "                        'estimated_salary':estimated_salary,\n",
    "                        'postDate':postDate,\n",
    "                        'extractDate':extractDate,\n",
    "                        'summary':summary,\n",
    "                        'url':url,\n",
    "                        'salary_and_jType':salary_and_jType,\n",
    "                        'sal_guide_items':sal_guide_items,\n",
    "                        'salfromsection':salfromsection,\n",
    "                        'job_type_items':job_type_items,\n",
    "                        'requirements':requirements,\n",
    "                        'description':description,\n",
    "                        'raw_desc_soup':raw_desc_soup}\n",
    "    if len(datapoint_dict) > 0:\n",
    "        return datapoint_dict\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(position, location):\n",
    "    \"\"\"[Conducts the web scraping process]\n",
    "    Args:\n",
    "        position ([string]): [job position for indeed.com query]\n",
    "        position ([string]): [job location for indeed.com query]\n",
    "        \n",
    "        Returns:\n",
    "        [csv]: [scraped data]\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # extract the job data\n",
    "    while True:\n",
    "        response = requests.get(get_URL(position, location))\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        searchResults = soup.find('div', id='mosaic-provider-jobcards')\n",
    "        refinedsearchResults = searchResults.find_all('div', attrs={'class': lambda e: e.startswith('cardOutline') if e else False})\n",
    "        \n",
    "\n",
    "        raw_posts = []\n",
    "        for post in refinedsearchResults:\n",
    "            raw_posts.append(post)\n",
    "        \n",
    "        n = 0\n",
    "        for post in raw_posts:\n",
    "            datapoint = get_features(post)\n",
    "            data = data.append(datapoint, ignore_index=True)\n",
    "        # Again, a nifty little workaround for evading detection.\n",
    "            n+=1\n",
    "            print(n)\n",
    "            \n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    name = position.replace(' ','_')\n",
    "    loc = location.replace(' ','_')\n",
    "    day = date.today()\n",
    "    # save the job data\n",
    "    data.to_csv(f'../app/data/scraped_{name}_{loc}_{day}.csv', index=False)\n",
    "    return raw_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabama\n",
      "1\n",
      "arkansas\n",
      "1\n",
      "arizona\n",
      "1\n",
      "california\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "colorado\n",
      "1\n",
      "2\n",
      "connecticut\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "delaware\n",
      "1\n",
      "2\n",
      "florida\n",
      "1\n",
      "georgia\n",
      "1\n",
      "2\n",
      "3\n",
      "remote\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "iowa\n",
      "1\n",
      "idaho\n",
      "1\n",
      "illinois\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "indiana\n",
      "1\n",
      "kansas\n",
      "1\n",
      "kentucky\n",
      "1\n",
      "louisiana\n",
      "1\n",
      "2\n",
      "massachusetts\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "maryland\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "maine\n",
      "1\n",
      "michigan\n",
      "1\n",
      "2\n",
      "3\n",
      "minnesota\n",
      "1\n",
      "missouri\n",
      "1\n",
      "mississippi\n",
      "1\n",
      "montana\n",
      "1\n",
      "north carolina\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "north dakota\n",
      "1\n",
      "nebraska\n",
      "1\n",
      "2\n",
      "new hampshire\n",
      "1\n",
      "new jersey\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "new mexico\n",
      "1\n",
      "nevada\n",
      "1\n",
      "new york\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "ohio\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "oklahoma\n",
      "1\n",
      "oregon\n",
      "1\n",
      "pennsylvania\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "rhode island\n",
      "1\n",
      "south carolina\n",
      "1\n",
      "south dakota\n",
      "1\n",
      "tennessee\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "texas\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "utah\n",
      "1\n",
      "virginia\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "vermont\n",
      "1\n",
      "2\n",
      "washington\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "wisconsin\n",
      "1\n",
      "west virginia\n",
      "1\n",
      "wyoming\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "state_names = [ \"alabama\", \"arkansas\",  \"arizona\", \"california\", \"colorado\", \"connecticut\", \"delaware\", \"florida\", \"georgia\", \"remote\", \"iowa\", \"idaho\", \"illinois\", \"indiana\", \"kansas\", \"kentucky\", \"louisiana\", \"massachusetts\", \"maryland\", \"maine\", \"michigan\", \"minnesota\", \"missouri\", \"mississippi\", \"montana\", \"north carolina\", \"north dakota\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"nevada\", \"new york\", \"ohio\", \"oklahoma\", \"oregon\", \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\", \"texas\", \"utah\", \"virginia\",  \"vermont\", \"washington\", \"wisconsin\", \"west virginia\", \"wyoming\"]\n",
    "for state in state_names:\n",
    "    position = 'data scientist'\n",
    "    location = state\n",
    "    print(state)\n",
    "    data = main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "position = 'data scientist'\n",
    "location = 'california'\n",
    "data = main(position,location )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = position.replace(' ','_')\n",
    "loc = location.replace(' ','_')\n",
    "day = date.today()\n",
    "data.to_csv(f'../app/data/scraped_{name}_{loc}_{day}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  below is used for various adjustments to my webscraping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Old Data With New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in state_names:\n",
    "    i = i.replace(' ','_')\n",
    "    lst.append(pd.read_csv(f'../app/data/scraped_data_scientist_{i}_2022-05-31.csv'))\n",
    "total = pd.read_csv(f'../app/data/total.csv')\n",
    "lst.append(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total = pd.read_csv(f'../app/data/total.csv')\n",
    "\n",
    "z = pd.concat(lst)\n",
    "z.to_csv('../app/data/total.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022-05-31'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.extractDate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>extractDate</th>\n",
       "      <th>job_type_items</th>\n",
       "      <th>location</th>\n",
       "      <th>postDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>raw_desc_soup</th>\n",
       "      <th>requirements</th>\n",
       "      <th>sal_guide_items</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_and_jType</th>\n",
       "      <th>salfromsection</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Global</td>\n",
       "      <td>Panjiva is a data-driven technology company th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>$91,500 - $190,100 a year -  Full-time</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>Working with our data scientists to turn large...</td>\n",
       "      <td>Data Engineer - Data Science Platforms &amp; Infra...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Global</td>\n",
       "      <td>Panjiva is a data-driven technology company th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>$91,500 - $190,100 a year -  Full-time</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>Working with our data scientists to turn large...</td>\n",
       "      <td>Data Engineer - Data Science Platforms &amp; Infra...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Data Scientist      If you are a Data Scient...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>Remote in Phoenix, AZ 85021</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.6</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$100,000 - $110,000 a year</td>\n",
       "      <td>$100,000 - $110,000 a year -  Full-time</td>\n",
       "      <td>$100,000 - $110,000 a year</td>\n",
       "      <td>Collaborate with analytics teams to create ins...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard Chartered</td>\n",
       "      <td>Job: Data and Analytics   Primary Location: As...</td>\n",
       "      <td>Estimated $105K - $133K a year</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco, CA 94105 (Financial District/So...</td>\n",
       "      <td>PostedJust posted</td>\n",
       "      <td>4.1</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', 'Not provided by employer', \"$105K - $133...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Develop machine learning and advanced analytic...</td>\n",
       "      <td>Specialist Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0c043ee62c575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primary Talent Partners</td>\n",
       "      <td>Primary Talent Partner has an exciting 12 mont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time', 'Contract']</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>PostedJust posted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>Bachelor's (Required)US work authorization (Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$65 - $70 an hour</td>\n",
       "      <td>$65 - $70 an hour -  Full-time, Contract</td>\n",
       "      <td>$65 - $70 an hour</td>\n",
       "      <td>Understanding of statistical modeling, machine...</td>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Remote Unity AI Engineer      If you are a R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>Remote in Seattle, WA 98109</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.6</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$100,000 - $200,000 a year</td>\n",
       "      <td>$100,000 - $200,000 a year -  Full-time</td>\n",
       "      <td>$100,000 - $200,000 a year</td>\n",
       "      <td>Experience with creating modding tools, or any...</td>\n",
       "      <td>Remote Unity AI Engineer</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>PhD degree with 4 years of applied research ex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Posted1 day ago</td>\n",
       "      <td>3.5</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Model accelerator and Data platform is loo...</td>\n",
       "      <td>Applied Science Manager, Model Accelerator and...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f088d36c6064a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Global</td>\n",
       "      <td>Panjiva is a data-driven technology company th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>$91,500 - $190,100 a year -  Full-time</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>Working with our data scientists to turn large...</td>\n",
       "      <td>Data Engineer - Data Science Platforms &amp; Infra...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Global</td>\n",
       "      <td>Panjiva is a data-driven technology company th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>$91,500 - $190,100 a year -  Full-time</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>Working with our data scientists to turn large...</td>\n",
       "      <td>Data Engineer - Data Science Platforms &amp; Infra...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Global</td>\n",
       "      <td>Panjiva is a data-driven technology company th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>['Full-time']</td>\n",
       "      <td>United States</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html dir=\"ltr\" lang=\"en\"&gt;\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>$91,500 - $190,100 a year -  Full-time</td>\n",
       "      <td>$91,500 - $190,100 a year</td>\n",
       "      <td>Working with our data scientists to turn large...</td>\n",
       "      <td>Data Engineer - Data Science Platforms &amp; Infra...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company  \\\n",
       "0                S&P Global   \n",
       "0                S&P Global   \n",
       "0               CyberCoders   \n",
       "0        Standard Chartered   \n",
       "1   Primary Talent Partners   \n",
       "..                      ...   \n",
       "3               CyberCoders   \n",
       "4   Amazon.com Services LLC   \n",
       "0                S&P Global   \n",
       "0                S&P Global   \n",
       "0                S&P Global   \n",
       "\n",
       "                                          description  \\\n",
       "0   Panjiva is a data-driven technology company th...   \n",
       "0   Panjiva is a data-driven technology company th...   \n",
       "0     Data Scientist      If you are a Data Scient...   \n",
       "0   Job: Data and Analytics   Primary Location: As...   \n",
       "1   Primary Talent Partner has an exciting 12 mont...   \n",
       "..                                                ...   \n",
       "3     Remote Unity AI Engineer      If you are a R...   \n",
       "4   PhD degree with 4 years of applied research ex...   \n",
       "0   Panjiva is a data-driven technology company th...   \n",
       "0   Panjiva is a data-driven technology company th...   \n",
       "0   Panjiva is a data-driven technology company th...   \n",
       "\n",
       "                  estimated_salary extractDate             job_type_items  \\\n",
       "0                              NaN  2022-05-31              ['Full-time']   \n",
       "0                              NaN  2022-05-31              ['Full-time']   \n",
       "0                              NaN  2022-05-31              ['Full-time']   \n",
       "0   Estimated $105K - $133K a year  2022-05-31                        NaN   \n",
       "1                              NaN  2022-05-31  ['Full-time', 'Contract']   \n",
       "..                             ...         ...                        ...   \n",
       "3                              NaN  2022-05-31              ['Full-time']   \n",
       "4                              NaN  2022-05-31                        NaN   \n",
       "0                              NaN  2022-05-31              ['Full-time']   \n",
       "0                              NaN  2022-05-31              ['Full-time']   \n",
       "0                              NaN  2022-05-31              ['Full-time']   \n",
       "\n",
       "                                             location           postDate  \\\n",
       "0                                       United States        PostedToday   \n",
       "0                                       United States        PostedToday   \n",
       "0                         Remote in Phoenix, AZ 85021        PostedToday   \n",
       "0   San Francisco, CA 94105 (Financial District/So...  PostedJust posted   \n",
       "1                                        San Jose, CA  PostedJust posted   \n",
       "..                                                ...                ...   \n",
       "3                         Remote in Seattle, WA 98109        PostedToday   \n",
       "4                                         Seattle, WA    Posted1 day ago   \n",
       "0                                       United States        PostedToday   \n",
       "0                                       United States        PostedToday   \n",
       "0                                       United States        PostedToday   \n",
       "\n",
       "    rating                                      raw_desc_soup  \\\n",
       "0      3.9  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "0      3.9  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "0      3.6  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "0      4.1  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "1      NaN  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "..     ...                                                ...   \n",
       "3      3.6  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "4      3.5  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "0      3.9  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "0      3.9  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "0      3.9  <!DOCTYPE html>\\n\\n<html dir=\"ltr\" lang=\"en\">\\...   \n",
       "\n",
       "                                         requirements  \\\n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "1   Bachelor's (Required)US work authorization (Re...   \n",
       "..                                                ...   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "\n",
       "                                      sal_guide_items  \\\n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0   ['', 'Not provided by employer', \"$105K - $133...   \n",
       "1                                                 NaN   \n",
       "..                                                ...   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "0                                                 NaN   \n",
       "\n",
       "                        salary                          salary_and_jType  \\\n",
       "0    $91,500 - $190,100 a year    $91,500 - $190,100 a year -  Full-time   \n",
       "0    $91,500 - $190,100 a year    $91,500 - $190,100 a year -  Full-time   \n",
       "0   $100,000 - $110,000 a year   $100,000 - $110,000 a year -  Full-time   \n",
       "0                          NaN                                 Full-time   \n",
       "1            $65 - $70 an hour  $65 - $70 an hour -  Full-time, Contract   \n",
       "..                         ...                                       ...   \n",
       "3   $100,000 - $200,000 a year   $100,000 - $200,000 a year -  Full-time   \n",
       "4                          NaN                                 Full-time   \n",
       "0    $91,500 - $190,100 a year    $91,500 - $190,100 a year -  Full-time   \n",
       "0    $91,500 - $190,100 a year    $91,500 - $190,100 a year -  Full-time   \n",
       "0    $91,500 - $190,100 a year    $91,500 - $190,100 a year -  Full-time   \n",
       "\n",
       "                salfromsection  \\\n",
       "0    $91,500 - $190,100 a year   \n",
       "0    $91,500 - $190,100 a year   \n",
       "0   $100,000 - $110,000 a year   \n",
       "0                          NaN   \n",
       "1            $65 - $70 an hour   \n",
       "..                         ...   \n",
       "3   $100,000 - $200,000 a year   \n",
       "4                          NaN   \n",
       "0    $91,500 - $190,100 a year   \n",
       "0    $91,500 - $190,100 a year   \n",
       "0    $91,500 - $190,100 a year   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Working with our data scientists to turn large...   \n",
       "0   Working with our data scientists to turn large...   \n",
       "0   Collaborate with analytics teams to create ins...   \n",
       "0   Develop machine learning and advanced analytic...   \n",
       "1   Understanding of statistical modeling, machine...   \n",
       "..                                                ...   \n",
       "3   Experience with creating modding tools, or any...   \n",
       "4   The Model accelerator and Data platform is loo...   \n",
       "0   Working with our data scientists to turn large...   \n",
       "0   Working with our data scientists to turn large...   \n",
       "0   Working with our data scientists to turn large...   \n",
       "\n",
       "                                                title  \\\n",
       "0   Data Engineer - Data Science Platforms & Infra...   \n",
       "0   Data Engineer - Data Science Platforms & Infra...   \n",
       "0                                      Data Scientist   \n",
       "0                           Specialist Data Scientist   \n",
       "1                                    Sr. Data Analyst   \n",
       "..                                                ...   \n",
       "3                            Remote Unity AI Engineer   \n",
       "4   Applied Science Manager, Model Accelerator and...   \n",
       "0   Data Engineer - Data Science Platforms & Infra...   \n",
       "0   Data Engineer - Data Science Platforms & Infra...   \n",
       "0   Data Engineer - Data Science Platforms & Infra...   \n",
       "\n",
       "                                                  url  \n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "0   https://www.indeed.com/rc/clk?jk=0c043ee62c575...  \n",
       "1   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "..                                                ...  \n",
       "3   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "4   https://www.indeed.com/rc/clk?jk=f088d36c6064a...  \n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "0   https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
       "\n",
       "[282 rows x 17 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix old imports\n",
    "\n",
    "data['extractDate']= pd.to_datetime(data['extractDate'])\n",
    "\n",
    "def pDate(row):\n",
    "    from datetime import datetime, date, timedelta\n",
    "\n",
    "    #days_ago = row['dateposted']\n",
    "    delta = timedelta(0)\n",
    "    try:\n",
    "        return row['extractDate'] - delta\n",
    "    except:\n",
    "        return row\n",
    "\n",
    "data['extractDate'] = data.apply( lambda row : pDate(row), axis = 1)\n",
    "data['extractDate'] = data['extractDate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../app/data/scraped_data_scientist_remote_2022-04-14.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.extractDate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac83f05b37eb5c5c49ba67e50f0047ddfbc4b30205fc79ee5f327b9c0ac37f55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "46216370387cf43888a1dc9433c5a4546bda9feed2ad4f35c2a851da9960dc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
